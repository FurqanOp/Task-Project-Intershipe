{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "3ia3WpFpUMY1",
        "outputId": "de4aad0e-41ff-47b1-88ad-a947d275b335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select a topic:\n",
            "1. Technology\n",
            "2. Sports\n",
            "3. History\n",
            "Enter the option number (1-3): 3\n",
            "\n",
            "Enter a paragraph related to History:\n",
            "Spain is a diverse and culturally rich country located in southwestern Europe, sharing the Iberian Peninsula with Portugal. With a population of around 47 million, its capital is Madrid, known for its grand boulevards, art museums, and royal palaces. Spain has a constitutional monarchy and is a member of the European Union. Historically, it played a dominant role during the Age of Exploration, building one of the largest empires in history. The country’s past includes Roman and Islamic influences, visible in landmarks like the Mezquita in Córdoba and the Alhambra in Granada. Spanish is the second most spoken native language in the world. The nation is renowned for its flamenco music and dance, bullfighting traditions, and world-class cuisine such as paella and tapas. Spain also has strong regional identities, with autonomous communities like Catalonia and the Basque Country having their own languages and cultural practices. It remains a top tourist destination globally.\n",
            "\n",
            "✅ MCQs generated:\n",
            "\n",
            "**Question 1:**\n",
            "\n",
            "What is the approximate population of Spain, according to the paragraph?\n",
            "\n",
            "a) 27 million\n",
            "b) 67 million\n",
            "c) 47 million\n",
            "d) 87 million\n",
            "\n",
            "**Correct Answer:** c) 47 million\n",
            "\n",
            "\n",
            "**Question 2:**\n",
            "\n",
            "Which of the following landmarks is NOT mentioned in the paragraph as showcasing Spain's diverse historical influences?\n",
            "\n",
            "a) The Mezquita in Córdoba\n",
            "b) The Alhambra in Granada\n",
            "c) The Sagrada Familia in Barcelona\n",
            "d) Royal Palaces in Madrid\n",
            "\n",
            "**Correct Answer:** c) The Sagrada Familia in Barcelona\n",
            "\n",
            "\n",
            "**Question 3:**\n",
            "\n",
            "According to the paragraph, what is the second most spoken native language in the world?\n",
            "\n",
            "a) English\n",
            "b) Mandarin Chinese\n",
            "c) Spanish\n",
            "d) French\n",
            "\n",
            "**Correct Answer:** c) Spanish\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# ✅ Set your Gemini API Key\n",
        "genai.configure(api_key=\"AIzaSyAiQjx-yZS-2g8etND80UNf7xlPoLF29ws\")  # Replace with your key\n",
        "\n",
        "# ✅ Load Gemini model\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
        "\n",
        "# ✅ Options\n",
        "options = [\"Technology\", \"Sports\", \"History\"]\n",
        "print(\"Select a topic:\")\n",
        "for idx, opt in enumerate(options, start=1):\n",
        "    print(f\"{idx}. {opt}\")\n",
        "\n",
        "# ✅ User selects topic\n",
        "while True:\n",
        "    try:\n",
        "        choice = int(input(\"Enter the option number (1-3): \"))\n",
        "        if 1 <= choice <= 3:\n",
        "            topic = options[choice - 1]\n",
        "            break\n",
        "        else:\n",
        "            print(\"Please enter a number between 1 and 3.\")\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "# ✅ User inputs paragraph\n",
        "paragraph = input(f\"\\nEnter a paragraph related to {topic}:\\n\").strip()\n",
        "\n",
        "if not paragraph:\n",
        "    print(\"❌ Paragraph cannot be empty.\")\n",
        "    exit()\n",
        "\n",
        "# ✅ Validate paragraph topic\n",
        "validation_prompt = f\"\"\"\n",
        "Is the following paragraph related to the topic \"{topic}\"?\n",
        "Reply only with \"yes\" or \"no\".\n",
        "\n",
        "Paragraph:\n",
        "\\\"\\\"\\\"\n",
        "{paragraph}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "validation_response = model.generate_content(validation_prompt)\n",
        "verdict = validation_response.text.strip().lower()\n",
        "\n",
        "# ✅ Proceed or reject based on validation\n",
        "if \"yes\" in verdict:\n",
        "    mcq_prompt = f\"\"\"\n",
        "    Generate 3 multiple-choice questions from the paragraph below.\n",
        "    Each question should have:\n",
        "    - A clear question\n",
        "    - 4 options (a, b, c, d)\n",
        "    - Print the correct answer at the end.\n",
        "\n",
        "    Paragraph:\n",
        "    \\\"\\\"\\\"\n",
        "    {paragraph}\n",
        "    \\\"\\\"\\\"\n",
        "    \"\"\"\n",
        "    mcq_response = model.generate_content(mcq_prompt)\n",
        "    print(\"\\n✅ MCQs generated:\\n\")\n",
        "    print(mcq_response.text)\n",
        "else:\n",
        "    print(\"\\n❌ Paragraph is not related to the selected option.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure your Gemini API Key\n",
        "genai.configure(api_key=\"AIzaSyAiQjx-yZS-2g8etND80UNf7xlPoLF29ws\")  # Replace with your actual API key\n",
        "\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
        "\n",
        "# Topic options\n",
        "options = [\"Technology\", \"Sports\", \"History\"]\n",
        "\n",
        "st.title(\"Paragraph-Based MCQ Generator\")\n",
        "topic = st.selectbox(\"Select a topic\", options)\n",
        "\n",
        "paragraph = st.text_area(f\"Enter a paragraph related to {topic}:\", height=200)\n",
        "\n",
        "if st.button(\"Generate MCQs\"):\n",
        "    if not paragraph.strip():\n",
        "        st.error(\"Paragraph cannot be empty.\")\n",
        "    else:\n",
        "        # Validate topic relevance\n",
        "        validation_prompt = f\"\"\"\n",
        "        Is the following paragraph related to the topic \"{topic}\"?\n",
        "        Reply only with \"yes\" or \"no\".\n",
        "\n",
        "        Paragraph:\n",
        "        \\\"\\\"\\\"\n",
        "        {paragraph}\n",
        "        \\\"\\\"\\\"\n",
        "        \"\"\"\n",
        "        validation_response = model.generate_content(validation_prompt)\n",
        "        verdict = validation_response.text.strip().lower()\n",
        "\n",
        "        if \"yes\" in verdict:\n",
        "            # Generate MCQs\n",
        "            mcq_prompt = f\"\"\"\n",
        "            Generate 3 multiple-choice questions from the paragraph below.\n",
        "            Each question should have:\n",
        "            - A clear question\n",
        "            - 4 options (a, b, c, d)\n",
        "            - Print the correct answer at the end.\n",
        "\n",
        "            Paragraph:\n",
        "            \\\"\\\"\\\"\n",
        "            {paragraph}\n",
        "            \\\"\\\"\\\"\n",
        "            \"\"\"\n",
        "            mcq_response = model.generate_content(mcq_prompt)\n",
        "            st.success(\"MCQs generated:\")\n",
        "            st.markdown(mcq_response.text)\n",
        "        else:\n",
        "            st.error(\"The paragraph is not relevant to the selected topic.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PauiomSHUNIM",
        "outputId": "64b57466-2888-41b3-afa0-4922635708a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Kill previous tunnels if any\n",
        "ngrok.kill()\n",
        "\n",
        "# Launch Streamlit app in background\n",
        "!streamlit run app.py &> /content/log.txt &\n",
        "\n",
        "# Connect to public URL\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Streamlit app running at:\", url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDPqyCxyWGLn",
        "outputId": "316b86af-4ffa-434e-f801-fbe08e8e69c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app running at: NgrokTunnel: \"https://2f28-34-139-43-126.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2tykSIV146iFJG5JKzBDlVp6osp_4yKYVXP9jkwAZRKkz39QZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUJ_wMs3WKmQ",
        "outputId": "c72ae6a3-1049-46dd-995d-90fcd2fab05b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TwKbUS0WSVA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}